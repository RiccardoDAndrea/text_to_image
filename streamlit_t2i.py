import streamlit as st
import torch
from diffusers import DiffusionPipeline
from streamlit_lottie import st_lottie

from utils import load_lottieurl
st.set_page_config(page_title="Text-to-Image Generator",
                   page_icon="ğŸ¨",
                   layout="centered")

st.title("ğŸ¨ Text-to-Image Locally")
creative_man = load_lottieurl('https://lottie.host/a2786f75-598c-457d-83b8-da7d5c45b91f/g06V88qWpk.json')
empty_chat_lottie = load_lottieurl('https://lottie.host/75cbdcf3-0356-4c8d-bfe3-5a278a262bb1/ShbsF9Vyu4.json')
welcome_page_tab1, Chat_tab2, info_for_models_tab3 = st.tabs([" :house: Home", 
                                                              " :statue_of_liberty: Text2ImageChat", 
                                                              " ğŸ¤— hugging face models"])

with welcome_page_tab1:
    creative_man_lottie_tab, welcome_text_tab = st.columns(2)

    # Introduction on what is text 2 Image
    with creative_man_lottie_tab:
        st_lottie(creative_man)
    with welcome_text_tab:
        st.markdown("""
                    # Welcome! ğŸš€

                    Hi, my name is **Riccardo D'Andrea** â€“ welcome to my **Text-to-Image Journey**! ğŸ˜Š  

                    I'm a **data scientist** and **deep learning enthusiast** from Germany ğŸ‡©ğŸ‡ª, and I'm excited to take you on an adventure into the world of **machine learning**.  

                    In this field, the unknown often becomes tangible ğŸ” â€“ Iâ€™ll help you understand it better and empower you to take action yourself ğŸ’¡.  

                    Let's explore together! ğŸ¤” Will we create new **image spaces** just from textâ€¦? ğŸŒˆâœ¨
                    """)
    

    st.divider()

    st.markdown("""
            # What is Text 2 Image? ğŸ¨âœ¨

            Imagine text-to-image models are like magical potions ğŸ§™â€â™‚ï¸: you give them a few words, and *voilÃ * â€“ they turn them into a picture! ğŸ–¼ï¸ğŸ’« These models use clever tricks from **artificial intelligence**, especially **computer vision** and **neural networks**, to transform simple text into complex, high-resolution images.

            **Hereâ€™s how it works:**

            1. Your text is first turned into numbers ğŸ”¢ â€“ a kind of â€œsecret languageâ€ the computer understands.  
            2. These numbers are fed into a neural network ğŸ§ , made up of layers of neurons. Each neuron thinks a little, mixes information, and wonders: â€œHmm, what could this image look like?â€ ğŸ¤”  
            3. Now comes the fun part: **diffusion** ğŸŒ«ï¸. The network builds the image step by step, like an artist painting layer by layer:  
            - First, a rough sketch is conjured âœï¸  
            - Then details are spread, adjusted, and polished ğŸ¨  
            - Step by step, until a stable, finished image emerges ğŸ–¼ï¸âœ¨

            The result? An image born from just a few words, almost like you poured your imagination into color! ğŸŒˆğŸ˜„

            **Why itâ€™s awesome:**  
            Text-to-image models can bring super creative ideas to life â€“ whether you want a cartoon, a scenic landscape, or a wacky fantasy creature. Theyâ€™re like tiny AI artists who never get tired ğŸ¨ğŸ¤–ğŸ’–.
            """)



    st.markdown("")
with Chat_tab2:
    # Sidebar Parameter
    user_num_inference_steps = st.sidebar.slider(
        label="inference steps",
        min_value=1,
        max_value=50,
        value=5,
        step=1,
    )
    
    # Pipeline laden
    def load_pipeline(model_path: str):
        pipe = DiffusionPipeline.from_pretrained(
            model_path,
            torch_dtype=torch.float16
        )
        pipe.enable_attention_slicing()
        pipe.enable_model_cpu_offload()
        return pipe

    @st.cache_resource
    def safe_load_pipeline(model_path: str):
        try:
            return load_pipeline(model_path)
        except OSError as e:
            
            # Mac File path explanation
            st.info(""" **Beispielpfade (Mac):**
            - `/Users/<USERNAME>/.cache/huggingface/hub/models--stabilityai--stable-diffusion-2-1`
            - `/Volumes/ExternalDrive/models/Juggernaut-XL-v9`""")
            
            # Windows File path explanation
            st.info(""" **Beispielpfade (Windows):**
            - `C:\\Users\\<USERNAME>\\.cache\\huggingface\\hub\\models--stabilityai--stable-diffusion-2-1`
            - `D:\\models\\Juggernaut-XL-v9`""")
            
            # Linux File path explanation
            st.info(""" **Beispielpfade (Linux):**
            - `~/.cache/huggingface/hub/models--stabilityai--stable-diffusion-2-1`
            - `/run/media/<USERNAME>/hard_drive/hub/Juggernaut-XL-v9`
            - `/home/<USERNAME>/models/Juggernaut-XL-v9`""")
            return f"âŒ Modell konnte nicht geladen werden.\n\nFehler: {e}"
        except EnvironmentError as e:
            return f"âŒ Problem beim Laden oder Herunterladen des Modells.\n\nFehler: {e}"
        except ValueError as e:
            return f"âŒ UngÃ¼ltiger Modellpfad: {e}"
        return None

    # Session-State initialisieren
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "pipe" not in st.session_state:
        st.session_state.pipe = None
    if "model_path" not in st.session_state:
        st.session_state.model_path = None

    # --- Container fÃ¼r Chat-Verlauf ---
    chat_container = st.container()

    with chat_container:
        for msg in st.session_state.messages:
            with st.chat_message(msg["role"]):
                if msg["type"] == "text":
                    st.write(msg["content"])
                elif msg["type"] == "image":
                    st.image(msg["content"], caption=msg.get("caption", ""), use_container_width=True)

    # --- Eingabe ganz unten, auÃŸerhalb des Containers ---
    user_input = st.chat_input("ğŸ‘‰ Modellpfad zuerst eingeben, danach Prompts...")
    if bool(user_input)==False:
        st_lottie(empty_chat_lottie,
                  width=600, height=300)
        st.info("Hey I am your Prime i am here to help you")
        st.info("Please give me your file path were you have saved your Models")
    if user_input:
        st.session_state.messages.append({"role": "user", "type": "text", "content": user_input})
        with chat_container:
            with st.chat_message("user"):
                st.write(user_input)

        if st.session_state.pipe is None:
            st.session_state.model_path = user_input
            with chat_container:
                with st.chat_message("assistant"):
                    st.write("ğŸ”„ Lade Modell...")
            pipe = safe_load_pipeline(st.session_state.model_path)

            if isinstance(pipe, str):
                st.session_state.messages.append({"role": "assistant", 
                                                  "type": "text", 
                                                  "content": pipe})
                with chat_container:
                    with st.chat_message("assistant"):
                        st.write(pipe)

            elif pipe is not None:
                st.session_state.pipe = pipe
                msg = "âœ… Modell erfolgreich geladen! Gib jetzt deinen Prompt ein âœ¨"
                st.session_state.messages.append({"role": "assistant", 
                                                  "type": "text", 
                                                  "content": msg})
                with chat_container:
                    with st.chat_message("assistant"):
                        st.write(msg)

        else:
            with chat_container:
                with st.chat_message("assistant"):
                    with st.spinner("Generiere Bild... bitte warten â³"):
                        try:
                            image = st.session_state.pipe(
                                user_input,
                                num_inference_steps=user_num_inference_steps
                            ).images[0]
                            st.image(image, caption=f"ğŸ–¼ï¸ Ergebnis fÃ¼r: {user_input}", use_container_width=True)
                            st.session_state.messages.append({
                                "role": "assistant",
                                "type": "image",
                                "content": image,
                                "caption": f"ğŸ–¼ï¸ Ergebnis fÃ¼r: {user_input}"
                            })
                        except Exception as e:
                            err_msg = f"âŒ Fehler bei der Bildgenerierung: {e}"
                            st.session_state.messages.append({"role": "assistant", 
                                                              "type": "text", 
                                                              "content": err_msg})
                            st.error(err_msg)

with info_for_models_tab3:
    st.header("Which Model can you use ğŸ¤—? ")
    st.info(""" 
            Models for Text 2 Image [Huggingface](https://huggingface.co/models?pipeline_tag=text-to-image&sort=trending)!
            """)
    st.write("""
            **Introduction:**

            This tool helps you select a suitable text-to-image model.

            Each model was trained on different images, so your model selection 
            is crucial.

            While one model was trained on photorealistic image diffusion, 
            another was trained on cartoon-like images.

            HuggingFace models have a comprehensive description of the model's purpose. 
            However, there are other models that do not have a description, 
            in which case an internet search is always helpful.

            """)

    # Button to open Model Catalog
    st.markdown("[Find your Models](https://huggingface.co/models?pipeline_tag=text-to-image&sort=trending)")
    # Select text to image model
    st.divider()
    models = ["RunDiffusion/Juggernaut-XL-v9", "Lykon/dreamshaper-7", "UnfilteredAI/NSFW-gen-v2"]
    selected_model = st.selectbox("Choose a Model:", models)

    if selected_model == 'RunDiffusion/Juggernaut-XL-v9':
        st.write("""
                **Model Details:**

                * Purpose: Dein persÃ¶nlicher Foto-Zauberer ğŸ§™â€â™‚ï¸ğŸ“¸ â€“ erschafft fotorealistische Bilder von Landschaften, Menschen oder Objekten, als hÃ¤tte er selbst eine Kamera in der Hand. Perfekt, wenn du realitÃ¤tsnahe Szenen brauchst oder ein Bild generieren willst, das fast wie ein Foto aussieht.

                * Training Data: Hochwertige, fotorealistische Bilder aus allen mÃ¶glichen Quellen. Alles wurde trainiert, damit das Modell Licht, Schatten und Perspektiven wie ein echter Fotograf versteht ğŸŒ„ğŸ’¡.

                * Besonderheit: Ideal fÃ¼r Projekte, bei denen die RealitÃ¤t tÃ¤uschend echt aussehen soll â€“ z.â€¯B. Produktbilder, Architekturszenen oder Portraits.  

                Important Source: [Juggernaut-XL-v9](https://huggingface.co/RunDiffusion/Juggernaut-XL-v9) ğŸ–¼ï¸
        """)

    elif selected_model == 'Lykon/dreamshaper-7':
        st.write("""
                **Model Details:**

                * Purpose: Der kreative Traum-Maler ğŸ¨ğŸ’­ â€“ perfekt fÃ¼r farbenfrohe, fantasievolle Kunstwerke. Anders als Juggernaut-XL zaubert Dreamshaper-7 eher Cartoon-, Manga- oder Illustrations-Stil, weniger fotorealistisch, dafÃ¼r voller Charakter und Stimmung.

                * Training Data: Cartoon- und Kunstbilder, Concept Art und Illustrationen. Die Bilder sind stilisiert und bunt â€“ als wÃ¼rdest du durch ein Kaleidoskop schauen ğŸŒˆâœ¨.  

                * Besonderheit: Ideal fÃ¼r Charakterdesigns, Storyboards, Comic-Kunst oder kreative Szenen, bei denen Realismus nicht das Ziel ist. Ein echtes Spielzeug fÃ¼r die Fantasie! ğŸ§¸ğŸ­  

                Important Source: [Lykon/dreamshaper-7](https://huggingface.co/Lykon/dreamshaper-7) ğŸ§©
        """)

    elif selected_model == 'UnfilteredAI/NSFW-gen-v2':
        st.write("""
                **Model Details:**

                * Purpose: Der rebellische Fotograf ğŸ“·ğŸ”¥ â€“ generiert realistische Bilder, oft mit erwachsenen Inhalten. Dieses Modell ist sehr leistungsstark, aber auch riskant, da es Inhalte erzeugen kann, die nicht jugendfrei oder rechtlich problematisch sein kÃ¶nnen.  

                * Training Data: Rohes, fotografisches Material aus verschiedenen Quellen. Das Modell hat keine strengen Filter, deshalb entstehen Inhalte, die verstÃ¶rend oder heikel sein kÃ¶nnen âš ï¸.  

                * Besonderheit: NSFW-gen-v2 eignet sich nur fÃ¼r verantwortungsbewusste Nutzung in sicheren, rechtlich zulÃ¤ssigen Umgebungen. Achtung: Es kann leicht zu problematischen Inhalten fÃ¼hren, also unbedingt Vorsicht walten lassen ğŸš¨.  

                Important Source: [UnfilteredAI/NSFW-gen-v2](https://huggingface.co/UnfilteredAI/NSFW-gen-v2?not-for-all-audiences=true) ğŸš€
        """)

